If you've been using Node since before containers,

you've probably done something in production like PM2, or

Forever, or Nodemon to manage your Node processes,

as well as scale those processes for multi

CPU servers.

What that really means is Node, by default, is

not multithreaded.

On most servers, you're going to have multiple CPUs.

Node won't take advantage of more than one of those CPUs by

default. In most Node apps,

you need to consider how you're going to run it across

multiple CPUs on a server,

and across multiple servers in a lot of cases.

Traditionally, before containers, we had things

like PM2, Forever Nodemon

and other tools that would spin up one or more

Node processes, running the same code, to be

able to run on multiple CPUs concurrently, and then it

would manage incoming connections and distribute it across

all those. Well, Docker does that for us.

So, whether you're using Docker, or Docker Compose,

or maybe Swarm, or Kubernetes, or ECS,

or some sort of container solution,

that solution is going to take into account how

you manage incoming connections, rather than these

older tools that we used before containers in

Node world.

So, think about it from the container manager point

of view. Realize that it's designed

to spin up multiple containers, and most solutions, they

call it replicas.

You're spinning up multiple replicas, which is copies

of that image, in multiple containers, all running

together.

A lot of solutions create some sort of load balancer for

talking about incoming connections.

They create load balancers in front of that to distribute

incoming connections. So, you don't need to worry about

those older tools. That's why throughout this course, I

have asked you to run Node directly in your container

images so that when your containers launch, there's

not this middle layer managing different

Node executables.

My general guideline for production systems

is to look at your Node apps, and of course you've got to

consider what kind of load you want to have, and you're

going to have to probably test some load stuff in order to

understand how your Node app is going to work.

But in general, in terms of CPU and consuming

all the CPU resources, you'll want to start one

to two containers per CPU,

assuming that you wanted to use all of the CPU resources

on that machine. If you had a cloud server, or some

data center server that had

two CPUs, then you would probably launch between four to

eight Node containers of that image

out-of-the-box. You may not need that many.

Maybe you only need a couple just to provide redundancy,

but you don't necessarily need more than that for capacity.

And that's fine. But, realize that when you're starting

up things in Docker, just because you have one or two Node

containers running, doesn't mean it's going to use all

those CPUs.

That Node limitation still exists in Docker, which is why

we want to start up replicas.

Swarm does this. Kubernetes does this.

Other orchestrators have this concept.

If you're using Docker Compose or Docker run, you're

going to use aliases and replicas in those

features as well.

When it comes to these containers inside of your CI,

be a little bit careful about when you run multiple

replicas, or containers, of your code inside

of CI. You want to know specifically why you're going to do

that because it's much harder to test when you've got

multiple copies of your app running there.

So, usually when you're doing unit testing, or other very

basic testing of your code, you're going to want to run

just one replica and have that single container output

all the things. If you get advanced in the CI, just

like any other solution, you could always spin up different

containers to run different tests.

That way, you could spread out your workloads and

distribute them so that your testing would go faster

instead of in a linear, synchronous fashion.

But, that doesn't really have anything to do with Node.

That's just how you design your CI system.

In general, for integration testing, I might consider using

multiple replicas if I have something that's like maybe

a Node API, or some middle layer of Node,

where I want to make sure that across different

containers running, that I still get the expected output

of my full integration and functional testing.

You might consider that as a part of your testing workflow.

Again, that part isn't really Node specific, but when it

comes to containers, it's so easy for us to spin up

multiple copies of these images into many containers

that we sometimes forget that there are design limitations

inherent in our application, that we may not realize

until we're running multiple copies of that same thing,

all at the same time.

