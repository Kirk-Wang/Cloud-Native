Hopefully you have done the assignment for writing a Node

Dockerfile for your own applications and that has gone

well. You've probably had to do some Internet research to

get exactly the lines. I'm going to do the same thing.

This is actually my first time running through it since I

created the assignment a little bit ago.

So, I may not get everything right on the first time.

I will be talking out loud, as usual, about my thought

process for what I need and why I need it.

Of course, the first thing we need to do is go through the

from line and figure out what Node image we need to start

from as our base image.

Let me go over here to

Docker Hub and go to

the Node image on Docker Hub just to make sure

that I need to use the Alpine

base image.

At the time here we're doing the 10 track, 10 15.

So, it looks like

there's the 10 15 Alpine right there.

One way when it's really hard for me to see all this stuff

and I can't find the thing I'm looking for, is I will do

either a control f or a command f, depending on what OS

you're on, and I will do something like a 10, like the

main version I'm looking for dash and then alpine

knowing that that's basically like an alias.

It's another tag, but it's an alias for whatever the latest

is in the 10 track.

If I want to do the same thing for 10 15, I could just

10.15 -alpine.

That would help me find the right one to make sure that I

have the right tag.

Now if you're doing this in a few months from the time

I've created it, and we're probably on 10.16

or 10.17.

So, at that time, you can still always use back

tags. So, old tags are around forever

as far as I know. Docker does not delete old base

official images because quite frankly,

all of our apps don't get updated all at the same time and

you can imagine the havoc it would cause if you had an

older Dockerfile that you tried to build, and then because

it's a couple of years old, that from image was no longer

available, and it basically failed the pull.

If that happened, then a lot of our deployments, especially

Enterprise deployments that are slower to update,

would start to fail. So, Docker keeps all those old

versions around. Those are up here under tags.

You can even look through here and even if....you

can see there's dozens, probably, of pages.

In fact, if I go to the very last page, there's 75 pages

of tags just for the Node image.

Obviously, there's a lot.

There's no real way to search through them, at least that

I'm aware of to search through all the tags.

So, it's best to either just try to pull

to see if you can pull that image and

if it works, then you know that tag is available.

So, let's let's give that a shot.

We're going to be back over here.

Because I'm using Visual Studio code, and I have

the Docker plugin, the advantage

there is that I get automatic image

searching capabilities. So, I can type in here node:10.15

and you can see it's already pre-populated the Alpine part,

so that helps. If I backed up, you could see that

10.15...it

may not return anything unless I get very specific.

Yeah. So it doesn't doesn't return

me a thousand results, right. It will only get me a few

when I do that. So, alpine.

All right. So, that's our first line.

Next, I know that we're supposed to expose something and

in this app, I'll need to go and look for

the package.json files.

So now that I'm in the package.json, I can

see...well it doesn't really tell me anything

about what ports. So, then the next thing I would want to

look at is the app itself.

So, this being a Node app, I'm going to pull

up the...what it says here is the main,

right, app.js, and I'll hopefully find what

port it's on there. This is part of the discovery process

of you having to basically deploy someone else's app.

You got to figure out what port it's on.

You know whether it's running on all IP addresses,

which is hopefully what it's doing.

In this particular app, it's running an app.js

file which was correctly identified in the package file, so

I knew that this was the startup one.

And that's usually if you're doing something like Express

or Hapi, or some the other more common web frameworks,

they'll usually have the server creation there with the

port. So, you could also just search all your code for the

word port and see if that comes up with something.

So, this launches on port 3000 on host 0000,

which is good because that's the default, meaning every

IP address on the machine, and when you're in a container,

the machine is essentially the container itself.

So, we want to make sure that it's not just listening on

localhost because that won't work in

a container. A container's localhost is basically

only in the container, not the physical host.

Now that we know port 3000.

All right. Now we're onto the next line.

According to the assignment, we're supposed to install tini

and start Node with tini.

I have a suspicion here that this run

line is probably where I need to use the package manager

to install tini before we copy

in source code. Because again, the idea of best practice

Dockerfile is that you're doing any sort of apt get, or

yum, or apk package installer

stuff, you're doing that before you copy in code.

Up here, I

can run the package manager for tini.

Maybe I don't know everything about Alpine's

package manager. Or maybe I don't know exactly the package

name for tini, so I'm going to have to go explore that.

It just so happens with tini, that if I just google

tini Docker, I'll come up with the

repo that uses this.

If I kind of search

around, I could actually do a control f and look for apk.

This shows how to pull the actual binary.

We don't need that. We can try to use the package manager.

Look at that. Alpine Linux package.

So run this apk install

no cache tini.

The no cache part makes sure that it's nice

and small. So, I can just delete this line and

copy that in, or paste that in rather.

Great.

Now we're onto the workdir.

The workdir here can be whatever you're comfortable with.

But, I would say make it consistent across your projects

and your company so that each one doesn't have a different

location. That way you can just get used to where the files

need to be. The sort of, some of the official standards

you might see, some standards under home/node.

Or, in my case you might have seen something under opt,

which is some sort of Linux standard around where you

should put these kind of files.

But honestly, I've seen /source, I've seen /node,

I've seen just about anything, /app.

Because it's inside a container, not everyone

is really obeying the traditional Linux rules, because you

don't necessarily need to worry about

file conflicts like you would on a massive file system

of a big server where you might have dozens and dozens of

applications installed, right.

This is just one container, with just one file system.

In my case, I'm going to make it simple and just

call it /app.

Typically, I would do copy copy

here like this. I would just do the dot dot, which means

everything from my working directory on the host to

everything in the container.

But then I'm realizing that part of the requirements is I

need to do the npm, right. I need to do the npm install

before I copy in all the source code.

So, I know that this one can't be the dot dot.

That one must be down here.

So this needs to be the npm install

and I'll come back to that in a minute.

And then this one's going to be copying in the package.json

files.

So, there are several ways to do this.

Probably the most literal is

package-lock.json and then something like that.

In fact, I could even put a little wildcard here.

That way, if the lock doesn't exist, it won't error out.

That's kind of what that wildcard would do for us there.

You could possibly just do a package*.json.That's

a shorter way.

When you're going to copy in multiple files though, this

back...this forward slash rather, is required.

So, that's why I have to put the dot and forward slash

here.

For the first run line, we know that we need to do the npm

install, and

we also need to clean up, just like we saw in the last

section when I talked about making efficient Dockerfiles.

We do an npm cache

clean force

and this will ensure that there's no leftover files

that are downloaded from the npm package repositories.

If I didn't say this before, the double ampersand

here means that the first command has to successfully

install before it will do a clean.

So, that's different than if you've ever seen a semicolon

there. A semicolon doesn't care if the first command

finishes correctly. It will just go ahead to the second one

and we definitely care when we are building to make sure

that every command works successfully.

So, that's why you always see double ampersands there.

Next, we're up to the entry point.

Now the entry point here is due to tini.

So, let's go back over to the tini documentation, and

we'll see that it talks about

that if you just put that entry point like this, then you

can run your app normally.

We had talked about that in the last sections.

Let's go ahead and paste that in there

like so and then at the end here,

we can simply run our node

app.js, right.

That's what we got from the package.json file.

If we go and double check that, it should be the

app.js as the main. Yep. So there we go.

We should be able to save

and let's see if we can build it.

docker build. We'll just do a tag

of assignment1.

All right. It looks like we built successfully.

So, let's try to run it.

docker run. I need to open up port 80

to 3000.

Then we're going to do assignment1 as

the image.

The server says it started.

Let's jump over to the browser.

Go to localhost port 80.

Now, you don't have to run yours on port 80 if it...if

you get a conflict on port 80, you can always map it to a

different port, like 8080 or 8888.

Basically, if you get any sort of error around permissions,

or bind mount, or port availability, or anything like that,

there's a lot of different errors depending on your

operating system and the version of Docker.

So, localhost

port 80. All right. I got my hello world, and

you can see that I'm getting the metadata in the logs

there, so it looks all great.

Hopefully it worked as well for you and I'll see in the

next lecture.

