Let's look at how we're going to do ARM, on your local machine, for development.

Again, this is for Docker Desktop only.

If you're using Linux Native, or if you're using Docker Toolbox, these options aren't available right

out-of-the-box.

There may be some workarounds you can look up online to set up a solution that would work for you,

but really right now, I'm just going to focus on Docker Desktop. There's several ways to get started

with this in your containers. Of course you need to start from images that are built for ARM, because

each image needs to be specific to the OS and architecture that's it's going to run, right.

So, Windows container images would be different than Linux container images. Just like Linux x86,

or as we call it in Docker, AMD64 compatibility architecture. There's ARM64 as well.

We just need to make sure that we're using an ARM-based image. The easy button here is to change

the from line from the official Node image default, which is AMD64 to one that is ARM64.

Usually, it's going to be the V8 version. There's other ARM processor additions that you can

look at for different architectures.

The most popular one now is the latest V8.

What's interesting in the background, is this will cause Docker Desktop to run ARM emulation in the

background on the processor, so that it'll run your container like it would normally run on a piece of

ARM hardware.

The way this works is through QEMU virtualization, or processor emulation, which is a common tool

on Linux for doing this sort of work where you're emulating one type of processor on another, and able

to run virtualization of those things.

So, it's something that Docker didn't invent.

They just built it into Docker Desktop, by default, as a bonus feature. QEMU is focused on running on

a standard Linux x86 AMD64 type solution, like

we'd all know in the cloud, or on your local machine, and then emulating a growing list of other processor

architectures. ARM is just one of those. Of course, there's multiple ARM processor types.

The one I'm here talking about is V8. Really after that, things just build and run like normal.

You're just going to build that image like you normally would. You can run it like you normally would.

It just so happens that it'll be running it on an emulated ARM computational stack.

The neat thing here is if you're in a larger solution where you have other containers, and maybe you want

to test some code that's going to eventually run on some sort of ARM device, but you also have other

code that needs to run on your standard x86 code,

you can run that in Compose together. Different containers can be mixed inside that single Compose file.

So, you could technically be editing different containers running at the same time, editing the code

on those from your local machine. And, they're running different processor architectures. Which is pretty

amazing. Let's look at an example and some of the sites that you need to check out in order to make

this all work. The first thing we need to concern ourselves with is making sure that our base image

is ARM-based, rather than the AMD64 that we're used to, by default.

If I'm over on Docker Hub. and I just go to the Node official image page, the easiest thing to do here,

right now, is to just scroll down until you see the architecture list. You'll see that there's AMD64,

ARM32v6, ARM32v7, i386, which is the old 32-bit kind of stuff, PPC64, S390, all these

different architectures.

Well, we've ignored that so far, right.

That's not really mattered to us.

But, if you just click on ARM64v8, then that will take you over to this official Node image page for

that specific architecture. You'll notice that the names are all the same because they're building

the same stuff, just with a different architecture type. That means I can copy this repo name here.

The actual organizational name is ARM64v8. I can go over to any Dockerfile that's running Node

and just swap out that from image, if I'm using the official image. I'm in the sample 02 directory.

We have a standard Dockerfile in there, and if I just take a look, that Dockerfile is pretty basic,

right.

It's just building a standard Node app with the basics. Nothing fancy in here.

If I just go in and add that organizational name, and put the slash in, then it tells Docker that this

is the image I want to use, and that image just happens to be built with a different architecture.

Now, you might wonder how we know about architectures, because they're not really obvious when you're

looking at stuff, right.

That's one of the things that Docker needs to improve on. But for now, you just basically do a docker

inspect. We can do a docker image inspect. Then, give the image name. In this case, we're going to

give it the ARM64.

If I just did a grep for architecture, you'll see that it says architecture is ARM64.

If I did that same thing without the option in the front there.

Oops.

Need to pull it. So, docker image pull node 10 Alpine.

If I run that same command there, you'll see that it's AMD64.

It's tricky, because if you look at both of them, they can get a little confusing. They're so similar.

But, they're quite different. They're totally different computer architectures.

They cannot work together, except for in this cool little emulation that we've got going on.

Now, I can just build this image since I've changed the Dockerfile to specify, or hardcode the ARM64

in there.

We're just going to call this ARM64 node.

If you see some unknown host little errors there,

don't worry about those.

They're just a part of the emulation software.

You can see that I have my image built.

If I did another inspect on that one, you would see that that image is also ARM based.

So, we can just do a docker run on that.

So, docker run, we'll do 8080 to port 3000 in the container, and we'll run it detached

and we called it ARM64 node.

If I do a docker ps, I should see that container running like we normally would have on a regular

AMD system.

If I jump over to my browser and go to localhost 8080, we'll see that sample app running.

Now, that's running a completely different architecture, but we really can't tell because it's Node. Node

works just about everywhere.

You can see that it's really easy for local development. From here,

the rest all still applies.

Everything else, in the rest of this course, still works the same way. The way you bind mount.

The way you develop. The way you network with it. It doesn't really matter. Because it's just emulating

that processor type.

