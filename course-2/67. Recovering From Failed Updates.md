All right. Remember the dashboard? Remember we set that up

earlier? If you still have the dashboard, pull that up In

another tab. If not, go back to the dashboard video

and redeploy that thing.

It'll still work great the same way as before.

It didn't have to be here all along.

Before we go to the dashboard, let's try one more command

from the command line to see how much information we can

get out of this from a single command.

I'm going to type kubectl describe deploy

workers. We're going to use that describe command, which if

you remember from early on in the course, is a really easy

way for a human to get a whole lot of different information

in one command. It kind of combines information into

a very easy, digestible format.

At first, when you look at something healthy, there's not

a lot of terribly interesting information there.

But, when it's unhealthy, suddenly you see the value of

this command. We have, at the bottom, some

events. What we want to see is here.

You can see that we now see,

if you can zoom into that, we can just zoom in a little

bit. You'll see the old and new ReplicaSets.

Now we can immediately tell, OK, we currently have two

ReplicaSets and that's not normal.

That's usually during a rolling update.

So, we want to keep scrolling up.

We want to see right

here replicas 10

desired, 5 updated, 13 total,

8 available and 5 unavailable.

Normally, this would just be 10 desired, 10

total. That would be 10, 10, 10, 10, 10 all the

way around along. So, the fact that these numbers are

inconsistent already tells us there's a problem.

The nice other things we can see here are things like the

rolling update strategy.

We can find out all that information in a single command.

But, let's jump back to looking at dashboard,

because a dashboard is always more interesting when there's

things broken.

The nice thing is that this dashboard from Kubernetes,

it's not really meant as a monitoring and logging tool, but

it does give us some value here of what's healthy

and what's not. We can now see reds in the pies,

the number of failed.

And if we scroll down, we can see that the worker

has an error. Failed to pull image

worker v0.3 error response

from daemon manifests not found manifest unknown manifest

unknown. So, then we can scroll down the pods.

We can see that each one of those unhealthy pods, it's

trying to get the image for the new container.

Those are in the image pull back off state.

So, we're seeing a lot of the information we could have got

from the command line. But of course, it's pretty.

So, this is pretty valuable, and this is just on the

overview page. So, we could probably dig around in here and

see slightly different views of things.

But, you get the point. This is a nice resource.

It's not...I wouldn't call it necessarily a troubleshooting

tool, but hey, it's a dashboard.

That's what it's there for, giving you that overview.

All right. Let's fix this thing.

We're in a broken state. We're technically trying to get

the version 3, but we mess up and the developers then

came back and told us, oh, we don't have a version 3.

You've got to go back to version 2.

How do we do that? How do we roll back what we just did?

And that is a rollout undo.

Let's look at the rollout undue command from

the command line.

kubectl rollout undo

deploy worker.

And it says we're rolled back.

Now, we can do that kubectl

rollout status deploy

worker.

And, this, if it's not live, if you're not getting it

while it's happening, it's going to give you the previous

last known status.

So, successfully rolled out.

We're good to go.

While we're here, let's just go back to our dashboard, see

what we see. Hit a refresh and

look at that.

We've got the greens across the board.

Green, green, green, green.

If you look at the deployments, the worker

now says the image it's using is worker v0.2.

They're in the middle of the screen.

Now we definitely know that we're back on v0.2.

If you look at the pod, you'll see that a lot of the

workers are only 33 seconds old, four,

to be exact.

And it's updating them.

All right. We've averted the crisis.

But, we are still in a problem

because we look back on our WebUI, and

we are back up to 8, but we're still at

a reduced performance from version 1.

So, how do we roll back even farther than the

v0.2? So, technically rolling back twice.

If we went back and we tried that same command

and it just did an undo again, and

then went back to our WebUI, and

hit refresh.

Uh oh. We're back in the same boat.

If we look down here at the worker, we're back at version

3. So, undo can't be used

more than once.

That's basically what I'm trying to tell you.

It turns out that the undo command is really

just flipping to the last one used.

Not necessarily the last good one or whatever.

It's not going down a stack of history.

It's simply undoing to the last one before that.

So, if you do it twice, you've basically reversed it,

right. So, we can't do that here.

That's a bad idea.

But, we can at least run it one more time

to get back to version 2.

So, let's do that. We'll hit the up arrow.

Now we're back at version 2.

Let's go back and look at our dashboard. Hit the refresh.

And, there we go.

All right. We're back to green.

All right. Don't want to do that again.

