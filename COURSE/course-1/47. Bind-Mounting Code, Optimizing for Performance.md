Now that we've gotten some of the little details about

Compose out of the way, let's focus on getting your code in

the container. Because this is deceptively simple, but

there are definitely a group of things that I see people

having problems with, or designing incorrectly, when

they're focusing on local development and bind mounting

their source code into a running container, right.

This is the ideal setup.

The whole reason we're trying to do this locally is so that

we can have all of our Node.js apps and its other

apps, like your databases and all the other stuff that's

going to be running, in your distributed app.

All these things are ideally going to be running on Linux

in production. That's the most likely case for Node.js.

You want to develop on that same system

and have all the conveniences of your different parts all

talking together of the same network.

Here, bind mounting of the code

is a little bit different on each operating system.

The first couple of gotchas that I want to make sure that

you're clear on is that in your Compose files, it

works best where everything is referenced as the parent

working directory or the pwd.

In this example here of my bad YAML in that

same directory that we had in the last lecture, the

my full path to the files

on the host.

That may work for you, but that's not how Compose is

supposed to work. Really, the left side of this bind mount

path should always just be a dot.

If it needs to be maybe up a directory, and move around,

it's always a relative path to the one you're

currently in. If you're in a big project, you're going to

have lots of different clones of repos,

probably in one master directory with a bunch of different

micro services maybe, in different subdirectories.

You could have one, large Compose file that

then bind mounts and runs a lot of different services.

That's totally fine.

In this line, you would then have a

../ that means back up a directory and then maybe bind

mount some path in a different directory.

Ideally, that's how your products are set up, right.

Usually, we don't get to run just one Git

repo. We usually have to download a bunch if we're in a

very large app, or just any old app, really.

You're going to be able to do that here.

No reason to do hard paths or fully qualified

paths. You don't want to do those because when you pass

these around your team, not everyone is going to have the

same path. So, it's definitely not going to work well.

And that's true on Windows, Linux and Mac.

Sometimes people on the Windows side get a little confused

because they see examples using the C drive and that's just

not needed when you're in a Compose file.

Docker run, sometimes you might need that depending

on if you can use the pwd variable.

But, here in the Compose, it's different.

In the Compose, we can always use the dot.

The one thing you don't want to do here is bind mount your

databases. I see this happen all the time.

It's a very common question.

If I scroll down in my bad YAML file here,

you definitely don't want to do this, where I'm bind

mounting my databases into some subdirectory.

That may seem like a good idea at first, but chances are

you're probably developing on Mac or Windows.

They don't work well across the OS boundary.

If you happen to be one of the lucky few

that are developing natively on Linux, and so your machine

that you're on every day with your GUI and everything is

pure Linux, then great.

You can bind mount all day because that's really the same

file system. It's just symlinking a little

path between one part of the file system and another.

If you're on Mac or Windows, these containers are running

in a different OS. They're running in a mini Linux VM.

These bind mounts are having to go over the

file IO path and even on the Windows side, it can be

even a little more tricky because it's actually using Samba

or SMB file shares, and that can really be slow if

you're in very large projects.

All right. The next tip here is that if you

are just using this Docker image for local

development, and you're doing a docker compose up with

a --build, or maybe you're doing a docker compose build,

you don't necessarily need to do that.

Not every time at least.

If you don't change your package file, then

just keep doing docker compose up.

You don't need to rebuild your images every

time you change code, right. That's not what we're here

for. We're not here to rebuild our images.

We're here to just develop and restart Node,

not restart the image build process.

If you think about it, you're mounting your host

files over top of the ones in the image

anyway. So, you technically could have an image with no

source code in it.

It just has your package dependencies from your Node

modules, and then your code you're bind mounting in.

In a lecture, in a little bit, of this same section, we'll

talk about how you get over the problem of your

Node modules on your host not getting into

your container, not interfering with the ones in your

container. That's a different setup.

We just need to change a few bits for that.

But for now, I want to reiterate that you can actually get

away with just doing a docker compose up, not rebuilding

the image every time until you change something with your

dependencies, or something about the Dockerfile itself.

Next up, a big deal here, is if you're on Windows

and you're developing on Windows for Node.js, or really

anything with Docker and Windows, you want to make sure you

go in the settings and you enable the permissions

for sharing the drive letter where your code is at.

Your code may not always be on C.

C is there by default.

If you're on a different partition.

Maybe you store your code on an external SSD or

something, then you need to go in there and check that box.

Also, if you have problems with files not sharing

properly into your container, then the common fix there is

to go back in your settings and uncheck that box,

and then recheck it. That will reinitialize the permissions

sharing thing that's going on in Windows that sometimes

gets broken, especially on Enterprise machines

where you're inside of an active directory and you have to

deal with Enterprise policies that might be affecting you.

Here on my Windows machine, I have my C

drive selected, but if I needed to put source code

on my E drive and share that into a container with a bind

mount, I would then need to check that box and apply it.

Again, if you wanted to sort of fix any sort of

inconsistencies, you could unchecked that, apply, then

recheck it and apply. That sort of refreshes things.

That's been a quirk for a few years now.

So, I'm pretty sure that's still an issue for certain

machines. You also might have a prompt for permissions

here that it asks you for a login and if your login is not

working, you need to get an admin log in.

You might even, in some cases depending on the security

settings of your machine, you need to get a local admin,

not a domain admin, if your box is on an active

directory domain, you might need to get a local account

created. There's a couple of different scenarios where

these things don't work right depending on corporate

policies. So, you might have to go down that road.

As a side note, you might be seeing a warning, at times, on

Windows, if you're developing on Windows and you're doing

builds on Windows.

A warning about file permissions.

This is something here at the bottom where you would see

security warning, you're building an image.

This is really talking about the difference between file

permissions on Windows and Linux, and how

Windows uses NTFS and Linux doesn't.

Over that share, the files that you would copy

into an image from Windows may not turn up in Linux

with the permissions you'd expect.

That is a common struggle for building when

you have your source code on Windows.

Every problem has a different solution there.

You might need to just make sure you're not building on

Windows if you have certain permission problems.

Or, you may need to design your Dockerfile to go and

check those permissions after every Docker build,

like a line down below in the Dockerfile that says, you

know, go and chown these files, or chmod

these files to certain settings that you need

in your app. Those are a couple of common Windows problems

when bind mounting.

Let's talk about performance for a minute, because this

comes up in larger projects, when people are getting

large amount of files, hundreds of package

dependencies.

This can get really big.

Bind mounts, because of that crossing the OS

boundary like we talked about, that can cause some serious

delays.

If you're on Mac OS, and you're using Docker Desktop, I

would like you to read a couple of resources on the Docker

website about file IO caching.

This is an interesting and complicated topic around how

Docker is tweaking Mac and Linux

in order for the files that you're bind mounting into the

container to have improved performance.

Because if you think about all the things that have to

happen in order for your Mac to tell a Linux machine,

over some special little connection, that a file has

changed, it actually turns out that this round trip can

cause around 100 milliseconds of delay.

Not a big deal. That sounds like a small fraction of time.

But when you're dealing with hundreds of thousands,

possibly millions of reads and writes, this can get

really, really slow.

I want you to read the references that I have in here

specifically for Mac OS in this lecture so that you fully

understand the different settings you can have here.

Because these are unique to Mac OS.

Then I'm going to show you an example here in my good

YAML. This good YAML shows a bind mount

of a directory, inside my parent working

directory, then under content, then it just mounts to some

place inside of the container.

But it has this delegated flag on the end.

That delegated flag tells Docker that

essentially, if there's writing going

on in the container, that it's okay for the container

file IO to get ahead of the host.

In other words, not every file IO

transaction has to be identical on host to

container. And, that if there's any reading or writing

going on in the container, that the container sort of wins

out and the host writing can catch up later.

This is handy when you're doing things like npm installs or

anything where you're maybe taking typescript files

and turning them into JavaScript, or taking a bunch of

static files like Hugo or one of these static site

generators, and turning a bunch of files into something

else. Maybe you're turning your CSS

into minification mode.

All these different things are doing lots of writes, and

there's a lot of potential for delay there that you

can help solve if you add delegated to every one

of these bind mounts on your Mac.

And I mean just about every one of them.

I default to putting it on there, and I have to come up

with good reasons not to do it.

You wouldn't normally do this if you were doing something

like a database because you wouldn't want your read/writes

to be out of sync.

It can cause different inconsistencies, but in general,

I have never experienced any of that.

Again, like we talked about in the last lecture, I

don't bind mount databases because that can just cause

problems anyway.

If you're on the Windows side, slightly different scenario.

You don't get that advance delegated mode or setting

the cache like you do on OS X because on Windows,

it's really using an SMB file share between Windows

and Linux. The disadvantage there is that it's

not quite as performant and there's not as a deep a level

of OS integration.

You're also on Windows dealing with the file permissions

and executable changes between Windows and Linux.

So, a couple of scenarios there if you get into trouble.

First, I should say that a whole lot of developers do just

fine, Node.js and Windows, and bind mounting stuff

in, and they don't need any special setup.

But, once you start hitting edge cases where things either

get really slow, or you start having problems that you just

can't resolve another way, a couple of options you have

there. One is to consider doing file synchronization

rather than linking the containers through a file share.

File sync tools, there's at least three of them that I know

of that are still at least being maintained.

Here's one called docker bg sync that runs

a file copying utility, essentially, in the background

that will copy files from your host into

the container and then your container's running them

natively in the container. There's a little bit of a

disadvantage there because you have a potential for more

delay of keeping files sync'd.

In general, the people that have figured out how to set

this up have told me that this works well for them,

especially when they're in larger projects and they maybe

have slow hard drives.

SSD's are definitely a thing you want to have if you're

doing Docker. But, if you can't have something like that,

then this might be an alternative to you.

It's outside the realm of the official Docker Desktop and

the support model there, but it does work for a lot of

people, so definitely check those tools out.

I give you a link to a few here in the references.

The other option you might consider is setting up the WSL

or Windows Subsystem for Linux.

Again, this is a little more advanced.

It's beyond what I really wanted to teach in this course

because it requires a lot of understanding and knowledge

about different shells, different setups, because

WSL is essentially a synthetic

Linux, or a Linux interpreter, inside

your windows machine that translates Linux

system calls into the windows kernel.

It's advanced stuff and it's super slick when it works

well, but it doesn't work in all cases.

Anyway, there's a great Readit about this from

another Docker Captain, Nick.

He talks about his setup of how he

is using WSL plus an optimized

bind mount configuration for his own development needs.

Again, this is definitely not for the faint of heart.

These are advanced setups that you probably shouldn't do

until you really need them.

And you will know you need them when things start to get

really slow, and you just can't take it anymore.

