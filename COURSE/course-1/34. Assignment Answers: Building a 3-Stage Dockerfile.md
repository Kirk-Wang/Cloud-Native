Hopefully, you've spent some time trying out the assignment

and getting your three stages clarified

in your Dockerfile, and trying to build each one of those

stages with the target options so that you can have three,

different images.

Now, you just kind of want to see how I do it and what

differs, right. Because if you can get your images working,

and you know, they're fine for you, then that's great.

My way might be a little bit different, might take some

different things into account. So, I will talk through this

as I go about it, and since I

gave you this helper file to start out your Dockerfile,

we know here that we have three stages.

They're in a certain order, and that each one is getting a

NODE_ENV. Of course, if you've not seen

NODE_ENV before, that is an environment variable that is

usually just used to state production or development, and

it can also say prod or dev.

That was made popular by the Express package.

It's not actually, as far as I'm aware, a built-in, node.js

option.

It's really more about the frameworks you're using and how

they might differ. It might enable caching, or

might enable different minifications of things, depending

on what you're using. So, in here we're assigning the

NODE_ENV, but you can always override that build at

time so that things would be different in each one these

stages. But typically, this is how you would see it

as default, right.

The first thing I want to deal with is the production.

I know that since production has to have the code in it,

and it has to have the package.json file, and it has to do

at least an npm install, I'm going to have those three

ingredients. I also know that, by the requirements,

I'm supposed to do a node command and not an npm command

to start this, right. So, if I just start to frame this

out, I know I have to do a copy of the package file

so I can actually just type this out.

In this case, I could do a package.json as sort of a

shortcut that allows me to have both files.

Doesn't really matter how you do that there.

Then I'm going to need to do an npm install.

In this case, one of the benefits, and this

isn't a requirement, but one of the benefits here is that I

can be very literal about what goes into the production and

what goes into development. So, in this case I could use

--production as an npm install option.

It also will read in the NODE_ENV.

But, the way I like to do it is --only=production.

Really, any of those three ways works.

In fact, if you just go look at the Node documentation

or the npm documentation, you'll see this stuff in there.

That ensures that my production image won't have the extra

things that it doesn't need that are just for development.

I'm also going to need to run a cleanup command

on the npm in order to make sure that it's small.

I can do that with a double

ampersand, and then npm cache clean.

Then give it the force option just like we did before.

Now I'm going to copy in the rest of my code.

Now, you can always use the best practices we talked about

earlier where you change working directory

and you make a specific place, and then you copy the code

into there. But, I'm trying to do this just for simplicity

and not adding in all the options that we've talked about

so far. This is really just focused on the multistage

part of this, but there's nothing wrong with you doing

that, right. Your production images are going to be more

complicated than this, but this is at least the minimum

that I need in order to get a working multistage.

Then finally in this stage, I'm going to do a cmd,

and that will allow me to put in the node command.

I can go look at the package.json file to see, okay,

so the start here has it running /bin/www.

So,

I'll put that in here.

All right. I'm going to save that file.

That's my first stage. Now, I could just try to build

this stage. I could actually just go type a docker

build command and not have to finish the other

two if I just wanted to test this one stage.

So, I could do something like a docker build

and I could call it multistage if I wanted.

Need to give it the t,

multistage and I have to target

it to that stage.

If you remember, the first one is called prod.

We gave it an easy name to remember so that we can refer to

it in commands and in the rest of this file.

I use the dot for the current directory.

All right. You'll see here that you don't see any of the

other lines, from the other stages, of this build.

If I left out the target option, it would build

all three stages and essentially it would do a top down

order and the image would be the result of all three of the

stages.

But, because I specified the target, it's only going to put

the first stage in this image.

Now, let's go to the second stage.

The second stage is focused specifically on my local

development. So, a couple of things are true here.

This image will probably never live in a repository or

registry. It won't ever list anywhere that

I care about the size of it other than my local machine.

Maybe I don't need to do an npm cache clean

because that little bit of savings that it might save for

me is not really that important on my local machine.

I really care more about quick build times.

Here we're going to need to install the dev dependencies

from our package.json because those were not installed in

the first stage.

If I go back to the package.json file, I'll see that I do

have some dev dependencies here.

So, I'm going to definitely need to do that command.

And that's probably what you would expect it to look like.

It's going to be a very similar command to the above.

I can do a run npm install

only

development. That will ensure that it doesn't waste its

time installing everything it already did in the first

stage. That's a big shortcut to save time.

It's only going to install those 4 other ones and make sure

that they're current. I don't need to do the cache clean

here just because this is only going to probably sit on my

local machine. I don't see myself putting this on a server

somewhere.

And, we're off to the next line.

So, the next line is really, at this point, just changing

the cmd. So, each stage as I go down the

Dockerfile is going to change

the cmd based on the environment it's going to run in.

You'll see in the from line that I'm froming

prod to dev and then down here, I'm froming dev to test.

So, once I get to the test stage, it

will essentially do the first stage first.

It will build that. Then it will build the second one.

Then it will build the third one. You could always have

these out of order and have

maybe the fourth stage later that's a different

type of dev setup, that based off a test.

So, you don't necessarily have to do everything in order,

but when we're not using buildkit, which we talked about a

few minutes ago, but we're not using buildkit here.

We're just using the multistage feature.

The thing is without buildkit, it's going to build from the

top down. So, even if the second stage, for example, wasn't

necessary to build the third one, let's say the third stage

said from prod as test,

it technically doesn't need that second stage to start the

third one. If we were using buildkit, one of the advantages

that you would see listed in the buildkit lecture is that

it will skip unnecessary stages.

We don't get that here with just the multistage feature

set. So, it's important to make sure that they're in order

so that we get the things we need, when we need them, and

not to reuse the lines twice.

If I were to put the test stage before the dev stage,

there might be things that I need to do twice because

the stages need different things at different times.

So, I have found that for me, at least, it works a little

bit better if I do the dev stage first.

Also, if I'm just targeting the dev stage for local

development, then it won't need to run the rest of the

lines for test just to give me that image for development.

So, back up here in the dev stage, I can go

back to the package.json to look at what the command

is for dev and pulling in...

so imagine this being a Node app that existed before

Docker, so they were using dev locally so someone

who wasn't using Docker would do npm dev,

or npm run dev, to start

the dev script. We're not going to do that here.

We want to put it straight in the Dockerfile so that it's

the default.

I could just copy this out, right.

I could just copy this line and then make it into

the JSON array that it needs to be in this line.

Give it some quotes and commas where they're needed.

And that should be it for the dev line.

Now, we're on to the test line.

And the test line won't need to install anything new

because the npm install, as a part of the dev

stage, got us all the dependencies, like Mocha

for testing. Really, all that's required here

is that we change the cmd.

We could always override at runtime and type

the npm test at the end of our docker run command.

But it might be easier from your workflow perspective,

or if using Docker Compose, it might be easier to

set this up like so.

That way, you have a specific

image that is just for testing the code.

Later on, we're going to get into a section around

development workflow with Docker Compose locally.

I'll be honest, this stage here, I would not use

locally so much because I would typically run a Docker

Compose exec command to jump right into the container and

run my test, real time, in the container from the CLI.

I Wouldn't necessarily have a separate image just for that.

However, this is great for Continuous Integration.

If you're using something like Jenkins, this is how you

would do testing. You would have it build an image, and the

image would run the test as a part of its build

process. And if any of the stages failed their commands,

then the image fails and your CI should not be

pushing the image up to the Internet, right.

So, a great way for Continuous Integration is to simply

add your test into it's own stage.

That stage here, we don't actually put the commands in.

We save that for putting in the package.json.

And you can see they go into the package.json.

The test command has me running Mocha test.

It might run a bunch of different tests.

It might run multiple ones with ampersands between

them. I won't have to go keep changing the

Dockerfile each time I want to change my testing

frameworks. I just know that the standard is npm test,

and I can do the rest of it in package.json.

So, I don't necessarily care.

The npm is running on the test infrastructure inside of

my Jenkins, or my Codeship, or CodeDeploy

in AWS, or whatever is building your container images,

because that thing is going to run the commands

and it's all automated. I don't have to worry about running

them locally myself.

Now, the final proof here is to run and build

these different images.

We've got to build them first, so let's do that one at a

time. I can go up here and do a docker

build. Well, in fact, we just did that, right.

We did a docker build of the multistage and targeted the

prod. So, I could do

that again and then add on docker run

that same image.

You'll see that it successfully ran my image, and in fact,

if I went to a browser and I hit refresh, and I had

published a port, which I didn't do, then I would see the

web app.

In this case, if you remember, we didn't add in tini.

So tini, you could have put that in

your Dockerfile for this assignment, and that's perfectly

fine. Tini would have worked well here.

I didn't put it in because it wasn't specifically necessary

just to show off multistage.

But, if you're doing that, you did it well.

You did it right. And because I can't control c out of

this. In fact, you know, it won't respond so I have the

same problem.

I'm going to need to open up another shell here and do a

docker stop on that container just to quit

it. So, for the second stage, you'll see that I did a

docker build and I just gave it a tag here of dev

so it would specify exactly this different image

we would target. Now the dev stage.

Then I'm adding the ampersands here just so that it'll do

both commands at one time. It will build it and then run

it. I'm throwing in the tini init

process, just so I can control c properly out of it this

time. Learning my lesson.

Then I'm publishing a port 3000.

If you were also doing this for local development, you

would probably want to bind mount with the volume.

That way, you get your code.

We'll cover that in a later section.

I can see now that my nodemon has started, and it's

watching the files.

If I hop over to my browser and go to localhost 3000,

I should see the app

running. Great. Okay. So we know that second stage is

working.

If I control c out of that, and I do the same thing for the

third stage. We'll call this test.

So, really all I need to do, and I don't need

to publish the port because it's just going to run a quick

test.

Then we'll change the target, and we'll change the image

name.

You don't have to change the image name each time, but it

will get confusing if you don't.

Because you'll end up with one image and you're not really

sure which stage that image has built into it.

So, I always end up building different image

tags, or just different image names altogether

so that I know which one of these I'm using.

You'll see that once it's run the docker run, it'll

actually run the Mocha test just like the npm command told

it to. It will run that sample check,

and then we're good.

I would actually see if it failed there at the command

line, it would exit improperly.

I could technically put this into my CI infrastructure.

If I ran the docker build command and then the docker run

command, I could do my test

on my CI infrastructure. Now, another way you could do CI,

which we'll talk a few times more throughout this course,

is I could put that npm test as an actual

line in the Dockerfile.

So instead of it being the cmd that runs from

the image, the idea is that while the image is building,

it's doing the npm test command as well.

And you could have that just be its own stage and

how that would look is that would simply, up here,

change this from a cmd to a run,

and just do npm test there.

Then down here, I could technically just not even have

a different cmd because in this case, what

I would do is I would have my test image build

on my CI infrastructure and if it successfully built,

I knew that it worked.

You could also, if you have a production situation where

you're just building the production image on your CI, you

might move this layer all the way up here.

So that right before it considers the image

a good image, it's run all the tests.

That's if you want your testing infrastructure to

not complete building of your images if the tests fail.

So, that's a little bit more of an automated way.

That way, you could potentially have your CI infrastructure

once it's successfully built the image, go ahead and push

that image up into your registry.