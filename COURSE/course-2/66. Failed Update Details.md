All right. From the last video, we're still sitting in a

rollout status. If I went back to my command line, you'd

see that we're, on the right here, still waiting for things

to finish. If we went looked at our WebUI,

we're still down.

We're even worse performance than before.

We're at six mines per second instead of the ten that we

were hoping to stay at.

We tried to deploy version 3.

It turns out version 3 is not there.

So, there's lots of reasons why that is.

But, before we get there, let's just do some quick basic

troubleshooting so you can maybe see how you could

tell what was going on.

The first way I might do this is I might just do a

kubectl get pods if

I'm in a small environment. If I'm in a large enviroment,

then I would have to do a selector

to only show me the workers.

But you can see here, I've got...let's

see, we've got one, two, three, four, five, six, seven,

eight running and five

in some sort of broken state.

We've got more than the 10, but five of them are

giving us errors. These are the status errors, and this is

coming from Docker. Docker, in this case, because we know

what we just did. It's saying image pull.

It can't pull the image and then ImagePullBackOff.

If you see errors or statuses that are about BackOff,

especially ImagePullBackOff, it's simply saying that

I've tried to pull the image. The image isn't working for

some reason. It could be we don't have authentication.

We don't have Internet access.

The registry is down so we can't pull the images.

It's the wrong image name.

There's all sorts of reasons why you get the same error.

The reason it's saying BackOff is because a lot of the

things in orchestration are designed

to not basically, denial of service the whole

system. So, you can imagine if we had a

whole bunch of these, all trying to pull a broken image,

they'd constantly be pinging in the registry, trying to

find the image over and over and over.

So, they have a BackOff feature that will slow

their roll over time.

So that essentially over time, they will ask less

and less for the image so that they don't essentially

denial of service something like the registry.

All right. If you go back over here, we can step through

what just happened, and this is all because

of our rolling update settings of MaxUnavailable

and MaxSurge both being at 25%.

The reason it's slower right now is because we have less

containers in a healthy state.

Our pods, we don't have 10 of them in a healthy state.

We have what was it?

One, two, three, four, five, six, seven, eight.

We have eight in a healthy state, five in an unhealthy

state. If we walk, line-by-line, it actually makes sense.

We know that because 25% can't be

three of ten, it can only stop two of ten.

So, it stopped the first two and then tried to replace

those. Because we have this MaxSurge at 25,

we can go up to 13.

So, it allowed us to create three more, essentially

giving us five that it's trying to start

with this new broken image.

Then, once that never finished, none of those became

healthy again, it's going to stop.

It's going to sort of freeze in place until we tell

it what to do next.

If you did this line-by-line, it would be...it stops two.

It then started two more.

Then, it started three more on top of that because of the

MaxSurge. If we had the MaxSurge at zero, it would

have never done this third line.

It would have only replaced the two.

When you talk about MaxSurge and MaxUnavailable, a lot of

these have to do with...the unavailable has to do with

you making sure that you never disrupt service.

So, you always have the minimum number that you need to

give your customer the service you need to give them.

The MaxSurge is really important

when your applications are very intensive.

If they need a lot of memory, you don't want to allow it to

spin up so many that it kills your server resources

and consumes everything that's extra on the top end, you

know. So, databases might have a very conservative

setting here, a very low setting here, so that it doesn't

kill your server's

resources, right. So, that 25% may or not be appropriate

depending on the application.

