Now we get to some Day-2 Operations.

You're a big shot now and you're

deploying production code in real time for your

customer. So, we can only do this on deployments,

DaemonSets and StatefulSets.

StatefulSets are for databases and things with persistent

data. We'll get to that later.

But, these are the really only ones we need this feature on

because everything else doesn't really make sense for

a rolling style update.

So, we're going to use some new commands.

They're underneath the kubectl rollout that will allow us

to see and control these rollout

features. We're going to do some watch commands on this

first one to see the different resources as

we do a rolling update of the worker deployment.

Imagine you're in production on version 0.1

of the worker.

You now need to deploy version 0.2 of

the worker. And for production,

should always be editing your YAML and using apply.

That's the declarative way to do it.

But, for us here in our lab setup,

it's just easier for us to do a one-liner that changes the

image in the spec.

So, we're going to do that here with a kubectl set image

command. Little bit easier than us constantly going in

editing. But again, this should not be

something you're tweaking in production because it doesn't

give you that history in a YAML and the consistency

and blah, blah, blah, right.

All right. You've been warned. So, let's go to the command

line. I have three different tabs

open. In addition, technically, four tabs

and around, we have the top right, we have the pods.

We're going to see those.

Then bottom right, we're going to see the ReplicaSets.

Bottom left,

we're going to see the deployments.

You see we have 10 workers and they're all running.

We're going to kubectl set image

deploy or deployment a worker.

And then worker again, worker=dockercoins/worker

with a tag this time of version 0.2.

And

away we go.

And You'll start to see the most interesting one up front

is the bottom left. You'll see the worker

count of something/something.

It'll go above 10 and then below 10.

And this all has to do with the maxSurge, right.

We're going potentially...we're starting new ones faster

than getting rid of old ones. So, there's an upper and

lower limit on the number of replicas we can

have. Then over on the top right, you see

the list of pots.

The interesting thing is the list of pods will

take longer to update than the workers itself,

maybe, because the workers looks like it's done, but you

still see stuff over in the top right say terminating.

So, why are those two not consistent?

That has to do with how our app is shutting down.

Our app is not a great app.

The worker was built by maybe someone who

doesn't know about proper shutdown of their apps.

The long story here is that Python, Node.js, some

other programming languages, they don't accept Linux

signals by default.

This is a Docker thing. This really isn't a Kubernetes

thing. If you're not aware of signals and proper

healthy shutdown of containers, definitely go check that

out on Google. There's tons of resources.

I talk about it a lot in my production

talks when I talk on stage and stuff because it's

a critical piece of proper updates is

to have proper shutdown, proper startup and the handing of

connections over.

But, that's a little bit beyond what we're trying to do

here. We're just try to understand what Kubernetes is doing

when the app isn't shutting down.

So, all those pods saying terminating, you

see, when I go back, I see all these terminating at the top

right.

That has to do with the fact that Kubernetes gave a signal

to these Python apps to say, hey, please, could

you shut down? And they're not shutting down right away.

And so Kubernetes is just waits for 30 seconds.

And if nothing happens, if they don't exit properly, or

improperly, just if they don't exit at all, it will send a

kill signal and terminate them.

And that takes 30 seconds.

It will give, by default, a 30-second grace period for

apps to shut down. You can change that, by the way, if you

have apps that need to do a long shutdown process, like

web servers that need to wait for TCP connections to

finish, right. Because you maybe have long polling or web

sockets. Well, you can totally handle all that with the

wait. But in this case, we didn't change the default.

So, it's 30 seconds.

It took 30 seconds. Then it killed them all.

So, that's part of it.

But if we go back to our Bitcoin miner, which you'll notice

is we were at 10, so we

started with the 10 workers.

We're back, by the way, if you're following along the whole

course, we're back to the rng being not

a DaemonSet. We're back to the rng being single server

deployment.

Because we don't have the multi-node setup, we're just

using rng. We've noticed that we now have a dip

in performance.

Let's go see what that's all about.

So, looks like our new version is

worse performing than our first version.

So, that's not good.

Let's try a new version.

We're going to deploy this a little bit differently this

time. We're still going to do the set image as a shortcut.

We're going to do version 3, but this is going to be an

example of what would happen if you send something out that

just doesn't exist.

If you've ever accidentally typed the wrong image name, or

a tag on an image that doesn't exist, you've probably seen

Docker errors before. This happens in Compose and any

container tool has that sort of

effects if you accidentally typed the wrong image because

certain things don't get validated.

One of the things in Kubernetes is because it's

asynchronous and it's declarative.

It's when you type these commands, it's not going to go and

validate the image and then immediately tell you, hey, that

image doesn't work.

So, we're going to have to investigate as things

happen to see if indeed this does

work. Let's go back to the command line.

We're going to do a rollout status

on this one, which will allow us to get...sort

of, we'll sit there and wait for the

deployment to finish.

OK. So on the left, we're doing kubectl set

image again.

deploy worker worker dockercoins worker

v0.3. It's not terribly important that you remember this

set syntax because it's not something you should be doing

in production. You should be editing YAML.

But, there's a lot of commands in Kubernetes that, you

know, allow you to do things different ways.

So, we're going to set that

to v3. Then we're going to set

the rollout status up so we can sit here and wait.

We can wait.

It's saying finishing 5 out of the 10 replicas.

And nothing's happening.

Let's go back to our miner screen and

see what's going on here.

We're getting worse.

So, it looks like we're about 25% lower than what we were

before. We keep making things worse.

We're now worried that we're going to get in trouble with

our boss. So, let's go to the next video and we'll

figure out what we just did.