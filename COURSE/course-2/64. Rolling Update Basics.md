We're going to talk now about one

of my favorite things, and that is rolling updates.

They're a critical part of what we call

Day-2 Operations. A lot of what we've done so far, not all,

but a lot of what we've done is what we call Day-1

Operation. Day-1 Operations means when

you're doing something for the first time. It's new. You're

setting up a fresh cluster. You're

deploying a brand new application. You're doing stuff for

the first time. But, you only get to do that on day one of

whatever the life of that thing is. After that, every day

from there until the end of the application's life, or

the cluster's life, those are called

Day-2 Operations. Historically, Day-2 has

been very hard to do. It's the worst part of the job

because we're always dealing with limiting tools

that don't do declarative deployments and don't have rolling updates

built in. Amazon was one of the first companies

to really get that right with their auto scaling groups,

but I'm not going to talk about our history.

Let's talk about what we can do now and the future of your

applications. And that is day-to-day rolling updates.

If you didn't have this feature in Kubernetes, then

we would just be taking down images and

taking down our applications every time we did updates.

But, in the world today, we can't do that.

We have to be up 24/7.

We have to be able to deploy multiple times a day and not

take down our client connections.

So, that's where rolling updates comes in.

It's

definitely one of the key features of any orchestrator, Kubernetes or any

of the other ones. With Kubernetes, when

a deployment is updated, when you change that deployment

spec, it's going to automatically do these

rolling updates. In the background,

this is creating multiple ReplicaSets. If you think about a

deployment, it normally just has one ReplicaSet and that

ReplicaSet has one or more pods.

But, when you start to do a rolling update in a deployment,

which again is your most common type typical

workload in Kubernetes.

When you start doing that update, it

will create a new ReplicaSet to create the

new containers. So, for the duration of your update

cycle, and depending on how many pods you have, that might

take seconds, it might take minutes or hours even.

During that time, there will be multiple ReplicaSets in

your deployment, the old and the new.

In fact, if you tend to sometimes

do updates while other updates are still happening, which

generally is not advisable just

because that gets really hard to track and it gets complicated. Usually

you want to let one finish, but sometimes you just can't.

You've realized during the middle of an update that

something's gone wrong and you have to do another update

while the first one is still running.

So, technically in that case, you could have multiple old

ReplicaSets all managed by the same deployment.

While there's certainly lots of things that will affect a

rolling update, the two that

we want to focus on right now are MaxUnavailable and

maxSurge. Those two key values will affect

several things about your deployment.

First, when you change these, they can

be one of two values. They can be an absolute number or

they can be a percent.

There's

sort of two, maybe three, rules here that help you remember

what these really do and affect.

I can't describe it any better than these lines.

So, let's just read them.

There will always be at least replicas minus maxUnavailable

pods available.

So, if we have ten replicas in our

deployment, and we set the maxUnavailable to

three, then there will always be seven

pods available.

That makes sense? Then, the next line is there

will never be more than replicas plus maxSurge pods in

total. The surge is where you're

adding new ones, the new ones that are starting up, how

many of those can start up at a time?

The maxUnavailable is the opposite.

How many can go down at a time?

You want to control this depending on the

number of replicas you have. So, it's

totally dependent on your application. So, if in that

second line, our maxSurge is also three, then we could

have no more than 13.

There will therefore, in the third line, be up

to maxUnavailable plus maxSurge pods being

updated at the same time.

Hopefully, that makes a little sense. We're going to go

through examples. We're going to actually do this at the

command line here in a minute. Of course, one

of the key features of any good rolling update process is

that you have failed states that you

can handle. You can roll back in case it doesn't

work out the way you intended. Let's just go to our command

line real quick and see what our current rollback

parameters are for DockerCoins.

You should have already rerun the kubectl apply

of our DockerCoins YAML so that we're back in that fresh

state.

We've got our ten workers. We've got our services and our

deployments, and we're going to type this a rather long

line. You could just type kubectl

get deploy output json,

and then read through the whole thing to find

these different parts.

Or, we could pipe it through the jq command.

Remember, if you need the jq and you don't have it, you can

use the shpod option to get all these tools.

Then we're going to type some stuff here.

What this is doing is dumping out the all

the deploys, all the deployments, and into a big JSON

array. Then we're going to use jq to parse through

them, break up the items, and we're going to add two

E-values in there.

The metadata names, we know the name of the deployment.

Then this spec.strategy.rollingupdate. That

will give us the values out of that part of the

of the JSON.

So, you'll see a nice little colored thing.

If you're on the right terminal, jq will color it for you.

You can see each one of these.

The dashboard has the defaults of maxSurge

25, 25. You can basically see that the defaults are 25%,

25%.

So, if we had, in the case of this worker, we had 10,

then 25% maximum,

could go beyond or below that.

That's really the one we're going to focus on because it

has 10. So, we can see each one of these pods

being replaced, versus other ones that will only have one

pod that gets replaced.