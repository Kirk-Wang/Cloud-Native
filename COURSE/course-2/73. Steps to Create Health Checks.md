When you go to start creating your healthchecks,

here is a list of questions you could ask yourself

on what you need to do for that particular container.

The first one is, do you want liveness, readiness

or both? Do you need a startup as well?

For the liveness and readiness, these technically could be

the same check in certain scenarios, but with different

thresholds for waiting.

Next, the easiest one is usually HTTP

for things that were responding as a Web server.

So, you're going to want to use those first before you go

writing custom scripts or doing raw TCP connections.

So, in order of ease and priority, can it do HTTP?

If not,

do we have a utility we can use in an exec command that

would give us intelligence?

And as a last resort, you can use TCP

connections because those aren't very intelligent.

It's simply checking for an open port.

Next, you would look and see if the app already has

something as an endpoint.

If it's going to use the HTTP method.

You might need to write something that

responds on a specific URL so you can do the code

that you need instead of maybe a default URL like the root,

or something like that. A lot of people use /health,

or /liveness, and /readiness.

Those are really valid examples because you would

know exactly which one of those URL's is used for

which Kubernetes check.

The next one is to balance, and this is an

art, to balance the

amount of things it's checking and all the stuff that this

healthcheck might do, and balance that against the amount

of resources that that check will require.

The third value here is how

often do you want to require it? An expensive check, like

we talked about earlier, where it maybe spikes

CPU for a brief second, you maybe only want

to run that every 10 seconds.

But, is your app one that you want it to

be able to check quicker because you don't want 10 seconds

of downtime?

Quite honestly, a lot of apps would be just fine with

15 or 30 seconds of waiting, and that would be a really low

rate in terms of making it expensive on

your CPU and resources because it would only be checking it

every 15 or 30 seconds.

Remember, this is per container.

So, if you had 10 replicas, every

time you do this, you're doing it 10 times.

You can start to imagine the

order of magnitude of processing that you could get to

pretty quickly if you had 10 replicas and a check every

second. That's 100 checks every

10 seconds. That seems like a lot, doesn't it?.

If it's an expensive check and it's doing a lot of

processing and validating of things, that's really going to

eat up some of your resources when there's

not any real work being done. Because if you think about

these healthchecks, they're just extra stuff, and they're

not even external monitoring

tools, which will also probably need to do some form of check. The

last one here is do we need to depend on any

external things for the readiness checks?

Again, this is only for readiness, but it's

allowed to go and look at other things. And, how does it do

that? Does it validate a database connection?

Does this healthcheck URL go ping a different API

endpoint to make sure that that's up?

You've got to be careful there because if you add to many

dependency checks, it could likely fail more

often, depending on if they're in your cluster or outside

your cluster. So, you have to balance that against all

these other factors.

